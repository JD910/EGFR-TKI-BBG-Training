{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EGFR-TKI-BBG-Training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"t0K8f75D1IWk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595371168140,"user_tz":420,"elapsed":12967610,"user":{"displayName":"jiangdian song","photoUrl":"","userId":"04830573807450151043"}},"outputId":"b781e770-7f4a-48f5-fcf1-8a4e19742870"},"source":["#https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/bigbigan_with_tf_hub.ipynb\n","import io\n","import IPython.display\n","import PIL.Image\n","from pprint import pformat\n","import numpy as np\n","import tensorflow as tf ##May report errors due to tensorflow versions\n","import tensorflow_hub as hub\n","import h5py\n","from datetime import datetime\n","from math import ceil\n","from random import shuffle\n","from sklearn import preprocessing\n","import os\n","import shutil\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","module_path = '/content/drive/My Drive/...Your BBG Model Path.../Bigbigan1'  # ResNet-50\n","os.chdir(module_path)\n","os.listdir(module_path)\n","\n","\n","with tf.Graph().as_default():\n","\n","  def interleave(*args):\n","    \"\"\"Interleaves input arrays of the same shape along the batch axis.\"\"\"\n","    if not args:\n","      raise ValueError('At least one argument is required.')\n","    a0 = args[0]\n","    if any(a.shape != a0.shape for a in args):\n","      raise ValueError('All inputs must have the same shape.')\n","    if not a0.shape:\n","      raise ValueError('Inputs must have at least one axis.')\n","    out = np.transpose(args, [1, 0] + list(range(2, len(a0.shape) + 1)))\n","    out = out.reshape(-1, *a0.shape[1:])\n","    return out\n","  def imgrid(imarray, cols=4, pad=1, padval=255, row_major=True):\n","    \"\"\"Lays out a [N, H, W, C] image array as a single image grid.\"\"\"\n","    pad = int(pad)\n","    if pad < 0:\n","      raise ValueError('pad must be non-negative')\n","    cols = int(cols)\n","    assert cols >= 1\n","    N, H, W, C = imarray.shape\n","    rows = N // cols + int(N % cols != 0)\n","    batch_pad = rows * cols - N\n","    assert batch_pad >= 0\n","    post_pad = [batch_pad, pad, pad, 0]\n","    pad_arg = [[0, p] for p in post_pad]\n","    imarray = np.pad(imarray, pad_arg, 'constant', constant_values=padval)\n","    H += pad\n","    W += pad\n","    grid = (imarray\n","            .reshape(rows, cols, H, W, C)\n","            .transpose(0, 2, 1, 3, 4)\n","            .reshape(rows*H, cols*W, C))\n","    if pad:\n","      grid = grid[:-pad, :-pad]\n","    return grid\n","  def imshow(a, format='png', jpeg_fallback=True):\n","    \"\"\"Displays an image in the given format.\"\"\"\n","    a = a.astype(np.uint8)\n","    data = io.BytesIO()\n","    PIL.Image.fromarray(a).save(data, format)\n","    im_data = data.getvalue()\n","    try:\n","      disp = IPython.display.display(IPython.display.Image(im_data))\n","    except IOError:\n","      if jpeg_fallback and format != 'jpeg':\n","        print ('Warning: image was too large to display in format \"{}\"; '\n","              'trying jpeg instead.').format(format)\n","        return imshow(a, format='jpeg')\n","      else:\n","        raise\n","    return disp\n","\n","  def image_to_uint8(x):\n","    \"\"\"Converts [-1, 1] float array to [0, 255] uint8.\"\"\"\n","    x = np.asarray(x)\n","    x = (256. / 2.) * (x + 1.)\n","    x = np.clip(x, 0, 255)\n","    x = x.astype(np.uint8)\n","    return x\n","\n","  module = hub.Module(module_path, trainable = True) # inference\n","  #module = hub.load(module_path) # inference\n","\n","  for signature in module.get_signature_names():\n","    print('Signature:', signature)\n","    print('Inputs:', pformat(module.get_input_info_dict(signature)))\n","    print('Outputs:', pformat(module.get_output_info_dict(signature)))\n","    print()\n","\n"," \n","\n","  #@tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n","\n","  def generate(z, upsample=False):\n","    \"\"\"Run a batch of latents z through the generator to generate images.\n","\n","    Args:\n","    z: A batch of 120D Gaussian latents, shape [N, 120].\n","\n","    Returns: a batch of generated RGB images, shape [N, 128, 128, 3], range\n","    [-1, 1].\n","    \"\"\"\n","    outputs = module(z, signature='generate', as_dict=True)\n","    return outputs['upsampled' if upsample else 'default']\n","\n","  def make_generator_ph():\n","    \"\"\"Creates a tf.placeholder with the dtype & shape of generator inputs.\"\"\"\n","    info = module.get_input_info_dict('generate')['z']\n","    return tf.placeholder(dtype=info.dtype, shape=info.get_shape())\n","\n","  def gen_pairs_for_disc(z):\n","    \"\"\"Compute generator input pairs (G(z), z) for discriminator, given z.\n","\n","    Args:\n","    z: A batch of latents (120D standard Gaussians), shape [N, 120].\n","\n","    Returns: a tuple (G(z), z) of discriminator inputs.\n","    \"\"\"\n","    # Downsample 256x256 image x for 128x128 discriminator input.\n","    x = generate(z)\n","    return x, z\n","\n","  def encode(x, return_all_features=False):\n","    \"\"\"Run a batch of images x through the encoder.\n","\n","    Args:\n","    x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n","        [-1, 1].\n","    return_all_features: If True, return all features computed by the encoder.\n","        Otherwise (default) just return a sample z_hat.\n","\n","    Returns: the sample z_hat of shape [N, 120] (or a dict of all features if\n","    return_all_features).\n","    \"\"\"\n","    outputs = module(x, signature='encode', as_dict=True)\n","    return outputs if return_all_features else outputs['z_sample']\n","\n","  def make_encoder_ph():\n","    \"\"\"Creates a tf.placeholder with the dtype & shape of encoder inputs.\"\"\"\n","    info = module.get_input_info_dict('encode')['x']\n","    return tf.placeholder(dtype=info.dtype, shape=info.get_shape())\n","\n","  def enc_pairs_for_disc(x):\n","    \"\"\"Compute encoder input pairs (x, E(x)) for discriminator, given x.\n","\n","    Args:\n","    x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n","        [-1, 1].\n","\n","    Returns: a tuple (downsample(x), E(x)) of discriminator inputs.\n","    \"\"\"\n","    x_down = tf.nn.avg_pool(x, ksize=2, strides=2, padding='SAME')\n","    \n","    z = encode(x)\n","    return x_down, z\n","\n","  def discriminate(x, z):\n","    \"\"\"Compute the discriminator scores for pairs of data (x, z).\n","\n","    (x, z) must be batches with the same leading batch dimension, and joint\n","    scores are computed on corresponding pairs x[i] and z[i].\n","\n","    Args:\n","    x: A batch of data (128x128 RGB images), shape [N, 128, 128, 3], range\n","        [-1, 1].\n","    z: A batch of latents (120D standard Gaussians), shape [N, 120].\n","\n","    Returns:\n","    A dict of scores:\n","        score_xz: the joint scores for the (x, z) pairs.\n","        score_x: the unary scores for x only.\n","        score_z: the unary scores for z only.\n","    \"\"\"\n","    inputs = dict(x=x, z=z)\n","    return module(inputs, signature='discriminate', as_dict=True)\n","\n","  def reconstruct_x(x, use_sample=True, upsample=False):\n","    \"\"\"Compute BigBiGAN reconstructions of images x via G(E(x)).\n","\n","    Args:\n","    x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n","        [-1, 1].\n","    use_sample: takes a sample z_hat ~ E(x). Otherwise, deterministically\n","        use the mean. (Though a sample z_hat may be far from the mean z,\n","        typically the resulting recons G(z_hat) and G(z) are very\n","        similar.\n","    upsample: if set, upsample the reconstruction to the input resolution\n","        (256x256). Otherwise return the raw lower resolution generator output\n","        (128x128).\n","\n","    Returns: a batch of recons G(E(x)), shape [N, 256, 256, 3] if\n","    `upsample`, otherwise [N, 128, 128, 3].\n","    \"\"\"\n","    if use_sample:\n","        z = encode(x)\n","    else:\n","        z = encode(x, return_all_features=True)['z_mean']\n","    recons = generate(z, upsample=upsample)\n","    return recons\n","\n","  def losses(x, z):\n","    \"\"\"Compute per-module BigBiGAN losses given data & latent sample batches.\n","\n","    Args:\n","    x: A batch of data (256x256 RGB images), shape [N, 256, 256, 3], range\n","        [-1, 1].\n","    z: A batch of latents (120D standard Gaussians), shape [M, 120].\n","\n","    For the original BigBiGAN losses, pass batches of size N=M=2048, with z's\n","    sampled from a 120D standard Gaussian (e.g., np.random.randn(2048, 120)),\n","    and x's sampled from the ImageNet (ILSVRC2012) training set with the\n","    \"ResNet-style\" preprocessing from:\n","\n","        https://github.com/tensorflow/tpu/blob/master/models/official/resnet/resnet_preprocessing.py\n","\n","    Returns:\n","    A dict of per-module losses:\n","        disc: loss for the discriminator.\n","        enc: loss for the encoder.\n","        gen: loss for the generator.\n","    \"\"\"\n","    # Compute discriminator scores on (x, E(x)) pairs.\n","    # Downsample 256x256 image x for 128x128 discriminator input.\n","    scores_enc_x_dict = discriminate(*enc_pairs_for_disc(x))\n","    scores_enc_x = tf.concat([scores_enc_x_dict['score_xz'],\n","                            scores_enc_x_dict['score_x'],\n","                            scores_enc_x_dict['score_z']], axis=0)\n","\n","    # Compute discriminator scores on (G(z), z) pairs.\n","    scores_gen_z_dict = discriminate(*gen_pairs_for_disc(z))\n","    scores_gen_z = tf.concat([scores_gen_z_dict['score_xz'],\n","                            scores_gen_z_dict['score_x'],\n","                            scores_gen_z_dict['score_z']], axis=0)\n","\n","    disc_loss_enc_x = tf.reduce_mean(tf.nn.relu(1. - scores_enc_x))\n","    disc_loss_gen_z = tf.reduce_mean(tf.nn.relu(1. + scores_gen_z))\n","    disc_loss = disc_loss_enc_x + disc_loss_gen_z\n","\n","    enc_loss = tf.reduce_mean(scores_enc_x)\n","    gen_loss = tf.reduce_mean(-scores_gen_z)\n","\n","    return disc_loss, enc_loss, gen_loss\n","\n","  with tf.Session() as sess:\n","\n","    lr = 0.0001\n","    batch_size = 20\n","    # Make input placeholders for x (`enc_ph`) and z (`gen_ph`).\n","    enc_ph = make_encoder_ph()\n","    gen_ph = make_generator_ph()\n","\n","    # Compute samples G(z) from encoder input z (`gen_ph`).\n","    gen_samples = generate(gen_ph)\n","\n","    # Compute reconstructions G(E(x)) of encoder input x (`enc_ph`).\n","    recon_x = reconstruct_x(enc_ph, upsample=True)\n","\n","    # Compute encoder features used for representation learning evaluations given\n","    # encoder input x (`enc_ph`).\n","    enc_features = encode(enc_ph, return_all_features=True)\n","\n","    # Compute discriminator scores for encoder pairs (x, E(x)) given x (`enc_ph`)\n","    # and generator pairs (G(z), z) given z (`gen_ph`).\n","    disc_scores_enc = discriminate(*enc_pairs_for_disc(enc_ph))\n","    disc_scores_gen = discriminate(*gen_pairs_for_disc(gen_ph))\n","\n","    # Compute losses.\n","    loss_disc, loss_enc, loss_gen = losses(enc_ph, gen_ph)\n","\n","    optimizer = tf.train.AdamOptimizer(lr, beta1 = 0.9)\n","\n","    train_op_disc = optimizer.minimize(loss_disc)\n","    train_op_enc = optimizer.minimize(loss_enc)\n","    train_op_gen = optimizer.minimize(loss_gen)\n","\n","    init = tf.global_variables_initializer()\n","    sess.run(init)\n","\n","    time = '{}'.format(datetime.now().strftime('%b%d_%H%M')) #运行新模型时使用\n","\n","    path = \"Training Data Path\"\n","    os.chdir(path) \n","    os.listdir(path)\n","\n","    for batch_index in range(200):\n","      \n","      with h5py.File(\"Training.hdf5\", 'r') as record:\n","        keys = list(record.keys())\n","        data_num = len(record)\n","        batches_list = list(range(int(ceil(float(data_num) / batch_size))))\n","        shuffle(batches_list)\n","        #print(batches_list)\n","        for n, i in enumerate(batches_list):\n","          i_s = i * batch_size  # index of the first image in this batch\n","          i_e = min([(i + 1) * batch_size, data_num])  # index of the last image in this batch\n","          Ori_img = []\n","          Number_batch = i_e - i_s\n","          Ori_img_name = keys[i_s:i_e]\n","          for is_p in range(i_s, i_e):\n","            image = np.array(record[keys[is_p]][\"train\"])\n","            if is_p == i_s:\n","              Ori_img = image\n","              Ori_img = np.expand_dims(Ori_img, axis = 0)\n","              #print(Ori_img.shape)\n","            else:\n","              image = np.expand_dims(image, axis = 0)\n","              Ori_img = np.append(Ori_img, image, axis = 0)\n","              #print(Ori_img.shape)\n","\n","          print(Ori_img.shape, n, i, batch_index)\n","          if((n + 1) % 1000 == 0):\n","            feed_dict = {gen_ph: np.random.randn(batch_size, 120)}\n","            _out_samples = sess.run(gen_samples, feed_dict=feed_dict)   \n","            #print('samples shape:', _out_samples.shape)\n","            imshow(imgrid(image_to_uint8(_out_samples), cols=4))\n","\n","            _out_recons = sess.run(recon_x, feed_dict={enc_ph: Ori_img})\n","            #print('reconstructions shape:', _out_recons.shape)\n","            inputs_and_recons = interleave(Ori_img, _out_recons)\n","            #print('inputs_and_recons shape:', inputs_and_recons.shape)\n","            imshow(imgrid(image_to_uint8(inputs_and_recons), cols=4))\n","          \n","          feed_dict = {enc_ph: Ori_img, gen_ph: np.random.randn(batch_size, 120)}\n","          _train_op_disc,_train_op_enc,_train_op_gen = sess.run(\n","            [train_op_disc, train_op_enc, train_op_gen], feed_dict=feed_dict)\n","          \n","          _out_scores_enc, _out_scores_gen, _loss_disc, _loss_enc, _loss_gen = sess.run(\n","            [disc_scores_enc, disc_scores_gen, loss_disc, loss_enc, loss_gen], feed_dict=feed_dict)\n","          #print('Encoder scores:', {k: v.mean() for k, v in _out_scores_enc.items()})\n","          #print('Generator scores:', {k: v.mean() for k, v in _out_scores_gen.items()})\n","          #print('Losses:', _loss_disc, _loss_enc, _loss_gen)\n","        \n","      if ((batch_index + 1) % 4 == 0 and lr > 1e-7):\n","        lr *= 0.5\n","\n","      if ((batch_index + 1) % 30 == 0):\n","        path = \"Save Model Path\"\n","        export_module_dir = os.path.join(path, \"Save Model Folder\")\n","        os.chdir(export_module_dir) \n","        shutil.rmtree(export_module_dir)\n","        os.mkdir(export_module_dir)\n","        module.export(export_module_dir, sess)\n","        \n","      path = \"Validation Data Path\"\n","      os.chdir(path) \n","      os.listdir(path)\n","      with h5py.File(\"Validation.hdf5\", 'r') as record:\n","        keys = list(record.keys())\n","        #print(keys)\n","        data_num = len(record)\n","        batches_list = list(range(int(ceil(float(data_num) / batch_size))))\n","        shuffle(batches_list)\n","        #print(batches_list) \n","        for n, i in enumerate(batches_list):\n","          i_s = i * batch_size  # index of the first image in this batch\n","          i_e = min([(i + 1) * batch_size, data_num])  # index of the last image in this batch\n","          Ori_img = []\n","          Number_batch = i_e - i_s\n","          Ori_img_name = keys[i_s:i_e]\n","          for is_p in range(i_s, i_e):\n","            image = np.array(record[keys[is_p]][\"train\"])\n","            if is_p == i_s:\n","              Ori_img = image\n","              Ori_img = np.expand_dims(Ori_img, axis = 0)\n","              #print(Ori_img.shape)\n","            else:\n","              image = np.expand_dims(image, axis = 0)\n","              Ori_img = np.append(Ori_img, image, axis = 0)\n","              #print(Ori_img.shape)\n","          _out_features = sess.run(enc_features, feed_dict={enc_ph: Ori_img})\n","\n","      path = \"Test Data Path\"\n","      os.chdir(path) \n","      os.listdir(path)\n","      with h5py.File(\"Test.hdf5\", 'r') as record:\n","        keys = list(record.keys())\n","        #print(keys)\n","        data_num = len(record)\n","        batches_list = list(range(int(ceil(float(data_num) / batch_size))))\n","        shuffle(batches_list)\n","        #print(batches_list) \n","        for n, i in enumerate(batches_list):\n","          i_s = i * batch_size  # index of the first image in this batch\n","          i_e = min([(i + 1) * batch_size, data_num])  # index of the last image in this batch\n","          Ori_img = []\n","          Number_batch = i_e - i_s\n","          Ori_img_name = keys[i_s:i_e]\n","          for is_p in range(i_s, i_e):\n","            image = np.array(record[keys[is_p]][\"train\"])\n","            if is_p == i_s:\n","              Ori_img = image\n","              Ori_img = np.expand_dims(Ori_img, axis = 0)\n","              #print(Ori_img.shape)\n","            else:\n","              image = np.expand_dims(image, axis = 0)\n","              Ori_img = np.append(Ori_img, image, axis = 0)\n","              #print(Ori_img.shape)\n","          _out_features = sess.run(enc_features, feed_dict={enc_ph: Ori_img})\n"]
